{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtkvrHs1332K",
        "outputId": "6fb40e1b-7aa9-433d-f836-2085ce5ffef9"
      },
      "source": [
        "# Set up colab instance\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qySM_YoE3-Oq",
        "outputId": "d972f69d-ab4d-482f-80b2-50e03e60fd4b"
      },
      "source": [
        "# Make sure clone at root\n",
        "!pip3 install pydicom\n",
        "!git clone https://github.com/thomasp05/gif-705-projet\n",
        "\n",
        "import os\n",
        "os.chdir('gif-705-projet')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydicom in /usr/local/lib/python3.6/dist-packages (2.1.1)\n",
            "fatal: destination path 'gif-705-projet' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYp93ihC4Amg",
        "outputId": "197a6499-eb2e-4448-a721-5113322908ff"
      },
      "source": [
        "import time\n",
        "\n",
        "import torch\n",
        "\n",
        "from dataset import *\n",
        "from models import *\n",
        "import models_parts\n",
        "\n",
        "torch.manual_seed(111)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fa86c0d7be8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpSCvWcH4Mqf"
      },
      "source": [
        "N_EPOCH = 1\n",
        "BATCH_SIZE = 4"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWzTP_VGANg2"
      },
      "source": [
        "class Downsample:\n",
        "  def __init__(self):\n",
        "    self.pool = nn.AvgPool2d(2)\n",
        "    \n",
        "  def __call__(self, x, target):\n",
        "    x = self.pool(x.unsqueeze(0)).squeeze(0)\n",
        "    target = self.pool(target)\n",
        "    return x, target"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKTBS6F14PJy",
        "outputId": "4015a6d3-d991-4f74-d774-b1cfa9046a23"
      },
      "source": [
        "dataset = dcm_dataset('../drive/MyDrive/GIF-7005-Projet/gif-7005-projet/data', transforms=Downsample())\n",
        "print(\"Found {} images\".format(len(dataset.img_files)))\n",
        "\n",
        "train_set, test_set = train_test_split(dataset)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    train_set, batch_size=BATCH_SIZE, num_workers=2)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    test_set, batch_size=BATCH_SIZE, num_workers=2)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 26684 images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUXipWIQ7jic"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    \"\"\"(convolution => [BN] => ReLU) * 2\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
        "        super().__init__()\n",
        "        if not mid_channels:\n",
        "            mid_channels = out_channels\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(mid_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "class Down(nn.Module):\n",
        "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.maxpool_conv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            DoubleConv(in_channels, out_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.maxpool_conv(x)\n",
        "\n",
        "\n",
        "class Up(nn.Module):\n",
        "    \"\"\"Upscaling then double conv\"\"\"\n",
        "\n",
        "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
        "        if bilinear:\n",
        "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
        "        else:\n",
        "            self.up = nn.ConvTranspose2d(in_channels , in_channels // 2, kernel_size=2, stride=2)\n",
        "            self.conv = DoubleConv(in_channels, out_channels)\n",
        "\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        x1 = self.up(x1)\n",
        "        # input is CHW\n",
        "        diffY = x2.size()[2] - x1.size()[2]\n",
        "        diffX = x2.size()[3] - x1.size()[3]\n",
        "\n",
        "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
        "                        diffY // 2, diffY - diffY // 2])\n",
        "        # if you have padding issues, see\n",
        "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
        "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
        "        x = torch.cat([x2, x1], dim=1)\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class OutConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(OutConv, self).__init__()\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
        "        super(UNet, self).__init__()\n",
        "        self.n_channels = n_channels\n",
        "        self.n_classes = n_classes\n",
        "        self.bilinear = bilinear\n",
        "\n",
        "        self.inc = DoubleConv(n_channels, 64)\n",
        "        self.down1 = Down(64, 128)\n",
        "        self.down2 = Down(128, 256)\n",
        "        self.down3 = Down(256, 512)\n",
        "        factor = 2 if bilinear else 1\n",
        "        self.down4 = Down(512, 1024 // factor)\n",
        "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
        "        self.up2 = Up(512, 256 // factor, bilinear)\n",
        "        self.up3 = Up(256, 128 // factor, bilinear)\n",
        "        self.up4 = Up(128, 64, bilinear)\n",
        "        self.outc = OutConv(64, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "        x5 = self.down4(x4)\n",
        "        x = self.up1(x5, x4)\n",
        "        x = self.up2(x, x3)\n",
        "        x = self.up3(x, x2)\n",
        "        x = self.up4(x, x1)\n",
        "        logits = self.outc(x)\n",
        "        return logits"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k5wsoFy04VPO"
      },
      "source": [
        "model = UNet(1, 1).to(\"cuda:0\")\n",
        "optim = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.BCEWithLogitsLoss()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsTUYSKxQsZP"
      },
      "source": [
        "## Train 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODcxS-Qx4cNQ",
        "outputId": "f2a617e7-c413-427d-88ac-5e848ad96de9"
      },
      "source": [
        "# Test inference\n",
        "timer = time.time()\n",
        "for epoch in range(N_EPOCH):\n",
        "  for img, (target, bounding_box) in train_loader:\n",
        "    \n",
        "    optim.zero_grad()\n",
        "\n",
        "    img = img.to(\"cuda:0\")\n",
        "    bounding_box = bounding_box.to(\"cuda:0\")\n",
        "\n",
        "    out = model(img)\n",
        "\n",
        "    loss = criterion(out, bounding_box)\n",
        "    loss.backward()\n",
        "\n",
        "    optim.step()\n",
        "\n",
        "  print(\"Epoch : {}\".format(epoch+1))\n",
        "  print(\"Time  : {:.2f}\".format(time.time()-timer))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1\n",
            "Time  : 4794.29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4iSHHyQ6hUG"
      },
      "source": [
        "checkpoint_path = \"unet.pt\"\n",
        "torch.save(model.state_dict(), checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tooj4rNs7ar3"
      },
      "source": [
        "checkpoint_path = \"/content/drive/My Drive/unet_drive.pt\"\n",
        "torch.save(model.state_dict(), checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0V_HX1t8y5U"
      },
      "source": [
        "checkpoint_path = \"/content/drive/My Drive/out_images_after_train.pt\"\n",
        "torch.save(out, checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjD6jetBQxQE"
      },
      "source": [
        "## Train 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rfZw-XkSwXQ"
      },
      "source": [
        "dataloaders = {\n",
        "  'train': train_loader,\n",
        "  'val': test_loader\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTGsMiiUSgLf"
      },
      "source": [
        "from collections import defaultdict\n",
        "\n",
        "\n",
        "# Source: A survey of loss functions for semantic segmentation https://arxiv.org/pdf/2006.14822.pdf\n",
        "def dice_loss(pred, target, smooth = 1.):\n",
        "    pred = pred.contiguous()\n",
        "    target = target.contiguous()    \n",
        "\n",
        "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
        "    \n",
        "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
        "    \n",
        "    return loss.mean()\n",
        "\n",
        "\n",
        "def calc_loss(pred, target, metrics, bce_weight=0.5):\n",
        "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
        "\n",
        "    pred = torch.sigmoid(pred)\n",
        "    dice = dice_loss(pred, target)\n",
        "\n",
        "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
        "\n",
        "    metrics['bce'] += bce.data.cpu().numpy() * target.size(0)\n",
        "    metrics['dice'] += dice.data.cpu().numpy() * target.size(0)\n",
        "    metrics['loss'] += loss.data.cpu().numpy() * target.size(0)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def print_metrics(metrics, epoch_samples, phase):\n",
        "    outputs = []\n",
        "    for k in metrics.keys():\n",
        "        outputs.append(\"{}: {:4f}\".format(k, metrics[k] / epoch_samples))\n",
        "\n",
        "    print(\"{}: {}\".format(phase, \", \".join(outputs)))\n",
        "\n",
        "\n",
        "def train_model(model, optimizer, scheduler, num_epochs = 25, checkpoint_path = \"checkpoint.pt\"):\n",
        "    best_loss = 1e10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        since = time.time()\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            metrics = defaultdict(float)\n",
        "            epoch_samples = 0\n",
        "\n",
        "            for inputs, (labels, bounding_box) in dataloaders[phase]:\n",
        "                \n",
        "                inputs = inputs.to(device)\n",
        "                #labels = labels.to(device)\n",
        "                bounding_box = bounding_box.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    loss = calc_loss(outputs, bounding_box, metrics)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                epoch_samples += inputs.size(0)\n",
        "\n",
        "            print_metrics(metrics, epoch_samples, phase)\n",
        "            epoch_loss = metrics['loss'] / epoch_samples\n",
        "\n",
        "            if phase == 'train':\n",
        "              scheduler.step()\n",
        "              for param_group in optimizer.param_groups:\n",
        "                  print(\"LR\", param_group['lr'])\n",
        "\n",
        "            # save the model weights\n",
        "            if phase == 'val' and epoch_loss < best_loss:\n",
        "                print(f\"saving best model to {checkpoint_path}\")\n",
        "                best_loss = epoch_loss\n",
        "                torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "        time_elapsed = time.time() - since\n",
        "        print('{:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val loss: {:4f}'.format(best_loss))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(torch.load(checkpoint_path))\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04pcIluOQyYX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b04976c-45cd-4123-c642-2719f1e1689b"
      },
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import models_parts\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print('device', device)\n",
        "\n",
        "optimizer_ft = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)\n",
        "\n",
        "exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=8, gamma=0.1)\n",
        "\n",
        "checkpoint_path = \"/content/drive/My Drive/intro_ml/unet_train_8_epochs.pt\"\n",
        "\n",
        "model = train_model(model, optimizer_ft, exp_lr_scheduler, 8, checkpoint_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "device cuda\n",
            "Epoch 0/7\n",
            "----------\n",
            "train: bce: 0.089442, dice: 0.903759, loss: 0.496600\n",
            "LR 0.0001\n",
            "val: bce: 0.078562, dice: 0.902831, loss: 0.490696\n",
            "saving best model to /content/drive/My Drive/intro_ml/unet_train_8_epochs.pt\n",
            "77m 56s\n",
            "Epoch 1/7\n",
            "----------\n",
            "train: bce: 0.083252, dice: 0.895242, loss: 0.489247\n",
            "LR 0.0001\n",
            "val: bce: 0.077742, dice: 0.897640, loss: 0.487691\n",
            "saving best model to /content/drive/My Drive/intro_ml/unet_train_8_epochs.pt\n",
            "78m 4s\n",
            "Epoch 2/7\n",
            "----------\n",
            "train: bce: 0.079627, dice: 0.890216, loss: 0.484921\n",
            "LR 0.0001\n",
            "val: bce: 0.075268, dice: 0.894736, loss: 0.485002\n",
            "saving best model to /content/drive/My Drive/intro_ml/unet_train_8_epochs.pt\n",
            "78m 9s\n",
            "Epoch 3/7\n",
            "----------\n",
            "train: bce: 0.182582, dice: 0.649170, loss: 0.415876\n",
            "LR 0.0001\n",
            "val: bce: 0.294598, dice: 0.257134, loss: 0.275866\n",
            "saving best model to /content/drive/My Drive/intro_ml/unet_train_8_epochs.pt\n",
            "78m 11s\n",
            "Epoch 4/7\n",
            "----------\n",
            "train: bce: 0.250561, dice: 0.303994, loss: 0.277277\n",
            "LR 0.0001\n",
            "val: bce: 0.298350, dice: 0.273893, loss: 0.286122\n",
            "78m 6s\n",
            "Epoch 5/7\n",
            "----------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9upLUv-7PyYD"
      },
      "source": [
        "Functions to plot images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzf05k4DMvaT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_img_array(img_array, ncol=3):\n",
        "    nrow = len(img_array) // ncol\n",
        "\n",
        "    f, plots = plt.subplots(nrow, ncol, sharex='all', sharey='all', figsize=(ncol * 4, nrow * 4))\n",
        "\n",
        "    for i in range(len(img_array)):\n",
        "        plots[i // ncol, i % ncol]\n",
        "        plots[i // ncol, i % ncol].imshow(img_array[i])\n",
        "\n",
        "from functools import reduce\n",
        "def plot_side_by_side(img_arrays):\n",
        "    flatten_list = reduce(lambda x,y: x+y, zip(*img_arrays))\n",
        "    plot_img_array(np.array(flatten_list), ncol=len(img_arrays))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRSw1MDIPfht"
      },
      "source": [
        "Left: Input image, Middle: Correct mask (Ground-truth), Rigth: Predicted mask"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONTTBiagNBmU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "64c7c769-2ecb-462c-9f61-e1124d003af6"
      },
      "source": [
        "plot_side_by_side([img.cpu().squeeze(), bounding_box.cpu().squeeze().numpy(), out.detach().cpu().squeeze()]) #\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-490fdc7294dc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_side_by_side\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbounding_box\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'img' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtclGIDTA28k"
      },
      "source": [
        "## Train 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7YuZPXgAjSF"
      },
      "source": [
        "class ResNetUNet(nn.Module):\n",
        "  def __init__(self, n_class):\n",
        "    super().__init__()\n",
        "\n",
        "    self.base_model = torchvision.models.resnet18(pretrained=True)\n",
        "    \n",
        "    avg_weights = torch.mean(self.base_model.conv1.weight, 1, True)\n",
        "    self.base_model.conv1 = nn.Conv2d(1, 64, 7, stride=2, padding=3, bias=False)\n",
        "    self.base_model.conv1.weight = nn.Parameter(avg_weights)\n",
        "    \n",
        "    self.base_layers = list(self.base_model.children())\n",
        "\n",
        "    self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n",
        "    self.layer0_1x1 = conv_relu(64, 64, 1, 0)\n",
        "    self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n",
        "    self.layer1_1x1 = conv_relu(64, 64, 1, 0)\n",
        "    self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n",
        "    self.layer2_1x1 = conv_relu(128, 128, 1, 0)\n",
        "    self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n",
        "    self.layer3_1x1 = conv_relu(256, 256, 1, 0)\n",
        "    self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n",
        "    self.layer4_1x1 = conv_relu(512, 512, 1, 0)\n",
        "\n",
        "    self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "\n",
        "    self.conv_up3 = conv_relu(256 + 512, 512, 3, 1)\n",
        "    self.conv_up2 = conv_relu(128 + 512, 256, 3, 1)\n",
        "    self.conv_up1 = conv_relu(64 + 256, 256, 3, 1)\n",
        "    self.conv_up0 = conv_relu(64 + 256, 128, 3, 1)\n",
        "\n",
        "    self.conv_original_size0 = conv_relu(1, 64, 3, 1)\n",
        "    self.conv_original_size1 = conv_relu(64, 64, 3, 1)\n",
        "    self.conv_original_size2 = conv_relu(64 + 128, 64, 3, 1)\n",
        "\n",
        "    self.conv_last = nn.Conv2d(64, n_class, 1)\n",
        "\n",
        "  def forward(self, input):\n",
        "    x_original = self.conv_original_size0(input)\n",
        "    x_original = self.conv_original_size1(x_original)\n",
        "\n",
        "    layer0 = self.layer0(input)\n",
        "    layer1 = self.layer1(layer0)\n",
        "    layer2 = self.layer2(layer1)\n",
        "    layer3 = self.layer3(layer2)\n",
        "    layer4 = self.layer4(layer3)\n",
        "\n",
        "    layer4 = self.layer4_1x1(layer4)\n",
        "    x = self.upsample(layer4)\n",
        "    layer3 = self.layer3_1x1(layer3)\n",
        "    x = torch.cat([x, layer3], dim=1)\n",
        "    x = self.conv_up3(x)\n",
        "\n",
        "    x = self.upsample(x)\n",
        "    layer2 = self.layer2_1x1(layer2)\n",
        "    x = torch.cat([x, layer2], dim=1)\n",
        "    x = self.conv_up2(x)\n",
        "\n",
        "    x = self.upsample(x)\n",
        "    layer1 = self.layer1_1x1(layer1)\n",
        "    x = torch.cat([x, layer1], dim=1)\n",
        "    x = self.conv_up1(x)\n",
        "\n",
        "    x = self.upsample(x)\n",
        "    layer0 = self.layer0_1x1(layer0)\n",
        "    x = torch.cat([x, layer0], dim=1)\n",
        "    x = self.conv_up0(x)\n",
        "\n",
        "    x = self.upsample(x)\n",
        "    x = torch.cat([x, x_original], dim=1)\n",
        "    x = self.conv_original_size2(x)\n",
        "\n",
        "    out = self.conv_last(x)\n",
        "\n",
        "    return out"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaIrzny3BqSI"
      },
      "source": [
        "model = ResNetUNet(1).to(\"cuda:0\")\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "for l in model.base_layers:\n",
        "  for param in l.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        " \n",
        "optim = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-4)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbHkcYb4CFUy",
        "outputId": "915df55e-71a0-4e80-cf25-8d08888bdb9b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Test inference\n",
        "timer = time.time()\n",
        "for epoch in range(N_EPOCH):\n",
        "  for img, (target, bounding_box) in train_loader:\n",
        "    \n",
        "    optim.zero_grad()\n",
        "\n",
        "    img = img.to(\"cuda:0\")\n",
        "    bounding_box = bounding_box.to(\"cuda:0\")\n",
        "\n",
        "    out = model(img)\n",
        "\n",
        "    loss = criterion(out, bounding_box)\n",
        "    loss.backward()\n",
        "\n",
        "    optim.step()\n",
        "\n",
        "  print(\"Epoch : {}\".format(epoch+1))\n",
        "  print(\"Time  : {:.2f}\".format(time.time()-timer))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch : 1\n",
            "Time  : 2418.16\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}